{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'CatBoostClassifier' from 'catboost' (c:\\G5-DScience\\G5_D.Scientist\\models\\catboost.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcatboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'CatBoostClassifier' from 'catboost' (c:\\G5-DScience\\G5_D.Scientist\\models\\catboost.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, f1_score, confusion_matrix, classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv('../data/stroke_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir características\n",
    "numeric_features = ['age', 'avg_glucose_level', 'bmi']\n",
    "categorical_features = ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status']\n",
    "\n",
    "# Crear preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(drop='first', sparse_output=False), categorical_features)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir escenarios y modelos\n",
    "scenarios = [\n",
    "    (\" *** Dataset Original *** \", df),\n",
    "    (\" *** Sin menores de 14 años ***\", df[df['age'] >= 14]),\n",
    "    (\" *** Sin valores desconocidos en Smoking Status\", df[df['smoking_status'] != 'Unknown']),\n",
    "    (\" *** Nueva categoría par desconocidos en Smoking Status\", df.replace({'smoking_status': {'Unknown': 'No Information'}}))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    (\"Logistic Regression\", LogisticRegression(random_state=42)),\n",
    "    (\"Random Forest\", RandomForestClassifier(random_state=42)),\n",
    "    (\"XGBoost\", XGBClassifier(random_state=42)),\n",
    "    (\"CatBoost\", CatBoostClassifier(random_state=42, verbose=False))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para evaluar el modelo y obtener métricas\n",
    "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    y_pred_proba_test = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    train_auc = roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])\n",
    "    test_auc = roc_auc_score(y_test, y_pred_proba_test)\n",
    "    \n",
    "    return {\n",
    "        \"train_auc\": train_auc,\n",
    "        \"test_auc\": test_auc,\n",
    "        \"f1_score\": f1_score(y_test, y_pred_test),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_pred_test).tolist(),\n",
    "        \"classification_report\": classification_report(y_test, y_pred_test, output_dict=True)\n",
    "    }\n",
    "\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre escenarios\n",
    "for scenario_name, scenario_df in scenarios:\n",
    "    print(f\"\\n--- Scenario: {scenario_name} ---\")\n",
    "    results[scenario_name] = {}\n",
    "    \n",
    "    # Dividir características y objetivo\n",
    "    X = scenario_df.drop('stroke', axis=1)\n",
    "    y = scenario_df['stroke']\n",
    "    \n",
    "    # Dividir en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Preprocesar datos\n",
    "    X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "    X_test_preprocessed = preprocessor.transform(X_test)\n",
    "    \n",
    "    # Iterar sobre modelos\n",
    "    for model_name, model in models:\n",
    "        print(f\"\\n{model_name}\")\n",
    "        results[scenario_name][model_name] = {}\n",
    "        \n",
    "        # Sin SMOTE\n",
    "        pipeline = Pipeline([('classifier', model)])\n",
    "        metrics_without_smote = evaluate_model(pipeline, X_train_preprocessed, X_test_preprocessed, y_train, y_test)\n",
    "        results[scenario_name][model_name][\"Without SMOTE\"] = metrics_without_smote\n",
    "        \n",
    "        # Con SMOTE\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train_preprocessed, y_train)\n",
    "        metrics_with_smote = evaluate_model(pipeline, X_train_smote, X_test_preprocessed, y_train_smote, y_test)\n",
    "        results[scenario_name][model_name][\"With SMOTE\"] = metrics_with_smote\n",
    "        \n",
    "        # Imprimir resultados\n",
    "        print(\"Without SMOTE:\")\n",
    "        print(f\"Train AUC: {metrics_without_smote['train_auc']:.4f}, Test AUC: {metrics_without_smote['test_auc']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics_without_smote['f1_score']:.4f}\")\n",
    "        print(\"\\nWith SMOTE:\")\n",
    "        print(f\"Train AUC: {metrics_with_smote['train_auc']:.4f}, Test AUC: {metrics_with_smote['test_auc']:.4f}\")\n",
    "        print(f\"F1-Score: {metrics_with_smote['f1_score']:.4f}\")\n",
    "        \n",
    "        # Evaluar overfitting\n",
    "        overfitting_without_smote = metrics_without_smote['train_auc'] - metrics_without_smote['test_auc']\n",
    "        overfitting_with_smote = metrics_with_smote['train_auc'] - metrics_with_smote['test_auc']\n",
    "        print(\"\\nOverfitting evaluation:\")\n",
    "        print(f\"Without SMOTE: {overfitting_without_smote:.4f}\")\n",
    "        print(f\"With SMOTE: {overfitting_with_smote:.4f}\")\n",
    "        \n",
    "        results[scenario_name][model_name][\"Overfitting\"] = {\n",
    "            \"Without SMOTE\": overfitting_without_smote,\n",
    "            \"With SMOTE\": overfitting_with_smote\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar resultados en un archivo JSON\n",
    "with open('stroke_prediction_results.json', 'w') as f:\n",
    "    json.dump(results, f, indent=4)\n",
    "\n",
    "print(\"\\nResults have been saved to 'stroke_prediction_results.json'\")\n",
    "\n",
    "# Visualización de importancia de características (para Random Forest)\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df['stroke']\n",
    "\n",
    "pipeline_rf = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "pipeline_rf.fit(X, y)\n",
    "\n",
    "feature_names = (numeric_features + \n",
    "                pipeline_rf.named_steps['preprocessor'].named_transformers_['cat'].get_feature_names_out(categorical_features).tolist())\n",
    "\n",
    "importances = pipeline_rf.named_steps['classifier'].feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(len(importances)), importances[indices])\n",
    "plt.xticks(range(len(importances)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_importances.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Feature importance plot has been saved as 'feature_importances.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterar sobre escenarios\n",
    "for scenario_name, scenario_df in scenarios:\n",
    "    print(f\"\\n*** ESCENARIO: {scenario_name} *** \")\n",
    "    \n",
    "    # Dividir características y objetivo\n",
    "    X = scenario_df.drop('stroke', axis=1)\n",
    "    y = scenario_df['stroke']\n",
    "    \n",
    "    # Dividir en conjuntos de entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    \n",
    "    # Iterar sobre modelos\n",
    "    for model_name, model in models:\n",
    "        print(f\"\\n{model_name} SIN técnicas de balanceo SMOTE:\")\n",
    "        \n",
    "        # Crear y entrenar pipeline sin SMOTE\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir y evaluar\n",
    "        y_pred = pipeline.predict(X_test)\n",
    "        y_pred_proba = pipeline.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "        print(f\"F1-Score: {f1_score(y_test, y_pred):.4f}\")\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred))\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred))\n",
    "        \n",
    "        print(f\"\\n{model_name} CON técnicas de balanceo SMOTE:\")\n",
    "        \n",
    "        # Crear y entrenar pipeline con SMOTE\n",
    "        pipeline_smote = ImbPipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('smote', SMOTE(random_state=42)),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        pipeline_smote.fit(X_train, y_train)\n",
    "        \n",
    "        # Predecir y evaluar\n",
    "        y_pred_smote = pipeline_smote.predict(X_test)\n",
    "        y_pred_proba_smote = pipeline_smote.predict_proba(X_test)[:, 1]\n",
    "        \n",
    "        print(f\"AUC-ROC: {roc_auc_score(y_test, y_pred_proba_smote):.4f}\")\n",
    "        print(f\"F1-Score: {f1_score(y_test, y_pred_smote):.4f}\")\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(confusion_matrix(y_test, y_pred_smote))\n",
    "        print(\"\\nClassification Report:\")\n",
    "        print(classification_report(y_test, y_pred_smote))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
